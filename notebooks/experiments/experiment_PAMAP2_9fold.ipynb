{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment PAMAP2 with mcfly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This turorial is intended to talk you through the functionalities of mcfly. As an example dataset we use the publicly available PAMAP2 dataset. It contains time series data from movement sensors worn by nine individuals. The data is labelled with the activity types that these individuals did and the aim is to train and evaluate a classifier.\n",
    "\n",
    "Before you can start, please make sure you installed all the dependencies of mcfly (listed in requirements.txt) and make sure your jupyter notebook has a python3 kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# mcfly\n",
    "from mcfly import tutorial_pamap2, modelgen, find_architecture, storage\n",
    "# Keras module is use for the deep learning\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution1D, Flatten, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "# We can set some backend options to avoid NaNs\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapath = '/media/sf_VBox_Shared/timeseries/PAMAP2_Dataset/slidingwindow512cleaned/'\n",
    "Xs = []\n",
    "ys = []\n",
    "\n",
    "ext = '.npy'\n",
    "for i in range(9):\n",
    "    Xs.append(np.load(datapath+'X_train_'+str(i)+ext))\n",
    "    ys.append(np.load(datapath+'y_train_binary'+str(i)+ext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create a model architecture. As we do not know what architecture is best for our data we will create a set of models to investigate which architecture is most suitable for our data and classification task. You will need to specificy how many models you want to create with argument 'number_of_models', the type of model which can been 'CNN' or 'DeepConvLSTM', and maximum number of layers per modeltype. See for a full overview of the optional arguments the function documentation of modelgen.generate_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = ys[0].shape[1]\n",
    "np.random.seed(123)\n",
    "models = modelgen.generate_models(Xs[0].shape,\n",
    "                                  number_of_classes=num_classes,\n",
    "                                  number_of_models = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare models\n",
    "Now that the model architectures have been generated it is time to compare the models by training them in a subset of the training data and evaluating the models in the validation subset. This will help us to choose the best candidate model. Performance results are stored in a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define directory where the results, e.g. json file, will be stored\n",
    "resultpath = '/media/sf_VBox_Shared/timeseries/PAMAP2_Dataset/results/' \n",
    "if not os.path.exists(resultpath):\n",
    "        os.makedirs(resultpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12373, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(ys[0:0]+ys[2:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_train_val(X_list, y_list, j):\n",
    "    X_train = np.concatenate(X_list[0:j]+X_list[j+1:])\n",
    "    X_val = X_list[j]\n",
    "    y_train = np.concatenate(y_list[0:j]+y_list[j+1:])\n",
    "    y_val = y_list[j]\n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 0 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 264s - loss: 5.4757 - acc: 0.2360 - val_loss: 1.8126 - val_acc: 0.4056\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 253s - loss: 2.9033 - acc: 0.3260 - val_loss: 1.6804 - val_acc: 0.4056\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 255s - loss: 2.7290 - acc: 0.3340 - val_loss: 1.6941 - val_acc: 0.4175\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 304s - loss: 3.7647 - acc: 0.4260 - val_loss: 1.4799 - val_acc: 0.4150\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 257s - loss: 2.7018 - acc: 0.5000 - val_loss: 2.0925 - val_acc: 0.3607\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 266s - loss: 3.1476 - acc: 0.4420 - val_loss: 2.7559 - val_acc: 0.0583\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 255s - loss: 2.1628 - acc: 0.4980 - val_loss: 1.9769 - val_acc: 0.3009\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 258s - loss: 2.3782 - acc: 0.5320 - val_loss: 3.6892 - val_acc: 0.0488\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 265s - loss: 1.7789 - acc: 0.5620 - val_loss: 1.2209 - val_acc: 0.4674\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 265s - loss: 2.5996 - acc: 0.5320 - val_loss: 1.0633 - val_acc: 0.6074\n",
      "Training model 1 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 215s - loss: 3.2630 - acc: 0.1240 - val_loss: 2.3866 - val_acc: 0.1006\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 210s - loss: 2.7568 - acc: 0.1500 - val_loss: 2.3509 - val_acc: 0.1345\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 206s - loss: 2.5551 - acc: 0.1480 - val_loss: 2.3687 - val_acc: 0.1345\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 197s - loss: 2.4595 - acc: 0.1340 - val_loss: 2.3504 - val_acc: 0.1345\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 195s - loss: 2.4150 - acc: 0.1480 - val_loss: 2.3536 - val_acc: 0.1345\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 195s - loss: 2.3953 - acc: 0.1380 - val_loss: 2.3395 - val_acc: 0.1345\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 194s - loss: 2.3989 - acc: 0.1420 - val_loss: 2.3675 - val_acc: 0.1345\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 196s - loss: 2.3954 - acc: 0.1420 - val_loss: 2.3431 - val_acc: 0.1345\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 200s - loss: 2.3837 - acc: 0.1420 - val_loss: 2.3623 - val_acc: 0.1345\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 197s - loss: 2.3980 - acc: 0.1400 - val_loss: 2.3398 - val_acc: 0.1560\n",
      "Training model 2 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 205s - loss: 2.6941 - acc: 0.1800 - val_loss: 2.2133 - val_acc: 0.3468\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 225s - loss: 2.4798 - acc: 0.2720 - val_loss: 2.5202 - val_acc: 0.2975\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 217s - loss: 2.4878 - acc: 0.2340 - val_loss: 2.0631 - val_acc: 0.3004\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 218s - loss: 2.3585 - acc: 0.2640 - val_loss: 1.6715 - val_acc: 0.3747\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 222s - loss: 2.1982 - acc: 0.2740 - val_loss: 1.8298 - val_acc: 0.3657\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 184s - loss: 2.1736 - acc: 0.2520 - val_loss: 2.3397 - val_acc: 0.3403\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 187s - loss: 2.2560 - acc: 0.2460 - val_loss: 1.4840 - val_acc: 0.4410\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 188s - loss: 2.0582 - acc: 0.2820 - val_loss: 1.6114 - val_acc: 0.3328\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 221s - loss: 1.9742 - acc: 0.2820 - val_loss: 1.7419 - val_acc: 0.2387\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 241s - loss: 2.0450 - acc: 0.2600 - val_loss: 1.4266 - val_acc: 0.4215\n",
      "Training model 3 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 40s - loss: 3.8232 - acc: 0.4520 - val_loss: 1.5998 - val_acc: 0.6079\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 37s - loss: 3.3814 - acc: 0.7460 - val_loss: 0.8361 - val_acc: 0.8296\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 40s - loss: 2.7987 - acc: 0.7980 - val_loss: 0.7829 - val_acc: 0.8500\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 39s - loss: 2.4219 - acc: 0.8160 - val_loss: 0.5507 - val_acc: 0.8675\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 37s - loss: 2.1166 - acc: 0.8780 - val_loss: 0.7929 - val_acc: 0.8271\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 43s - loss: 1.8743 - acc: 0.8940 - val_loss: 0.8460 - val_acc: 0.7529\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 37s - loss: 1.7295 - acc: 0.9000 - val_loss: 0.5971 - val_acc: 0.8809\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 37s - loss: 1.7153 - acc: 0.8820 - val_loss: 0.7879 - val_acc: 0.8430\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 37s - loss: 1.6220 - acc: 0.8900 - val_loss: 0.7036 - val_acc: 0.8366\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 37s - loss: 1.5159 - acc: 0.9160 - val_loss: 0.6276 - val_acc: 0.8520\n",
      "Training model 4 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 30s - loss: 2.4105 - acc: 0.4340 - val_loss: 1.3869 - val_acc: 0.6487\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 31s - loss: 1.6814 - acc: 0.7760 - val_loss: 1.0666 - val_acc: 0.7534\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 33s - loss: 1.4878 - acc: 0.8520 - val_loss: 0.9739 - val_acc: 0.7798\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 38s - loss: 1.3357 - acc: 0.9200 - val_loss: 1.0017 - val_acc: 0.7798\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 39s - loss: 1.2243 - acc: 0.9400 - val_loss: 1.0131 - val_acc: 0.7857\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 34s - loss: 1.1845 - acc: 0.9480 - val_loss: 1.0485 - val_acc: 0.7384\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 32s - loss: 1.1730 - acc: 0.9480 - val_loss: 1.0060 - val_acc: 0.7678\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 34s - loss: 1.1899 - acc: 0.9520 - val_loss: 0.9580 - val_acc: 0.7798\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 37s - loss: 1.1298 - acc: 0.9580 - val_loss: 0.9987 - val_acc: 0.7638\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 31s - loss: 1.1300 - acc: 0.9620 - val_loss: 0.9857 - val_acc: 0.7803\n",
      "Training model 5 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 56s - loss: 45.8359 - acc: 0.4200 - val_loss: 1.7010 - val_acc: 0.3866\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 63s - loss: 26.8179 - acc: 0.6440 - val_loss: 1.8749 - val_acc: 0.3787\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 61s - loss: 10.2237 - acc: 0.6680 - val_loss: 1.6575 - val_acc: 0.3911\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 66s - loss: 5.6751 - acc: 0.6220 - val_loss: 1.0674 - val_acc: 0.6866\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 74s - loss: 4.2345 - acc: 0.6280 - val_loss: 1.5649 - val_acc: 0.5117\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 66s - loss: 3.3261 - acc: 0.6860 - val_loss: 1.7970 - val_acc: 0.3991\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 63s - loss: 3.0364 - acc: 0.6240 - val_loss: 1.9051 - val_acc: 0.5705\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 58s - loss: 2.9418 - acc: 0.6060 - val_loss: 2.3979 - val_acc: 0.5690\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 59s - loss: 2.7852 - acc: 0.6360 - val_loss: 1.6595 - val_acc: 0.5740\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 60s - loss: 2.5834 - acc: 0.6440 - val_loss: 3.1810 - val_acc: 0.4310\n",
      "Training model 6 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 251s - loss: 12.0243 - acc: 0.1240 - val_loss: 2.3680 - val_acc: 0.1345\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 241s - loss: 4.5658 - acc: 0.1660 - val_loss: 2.3858 - val_acc: 0.1345\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 285s - loss: 3.4981 - acc: 0.1260 - val_loss: 2.3532 - val_acc: 0.1345\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 251s - loss: 2.8807 - acc: 0.1300 - val_loss: 2.3584 - val_acc: 0.1345\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 217s - loss: 2.6531 - acc: 0.1460 - val_loss: 2.3612 - val_acc: 0.1345\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 242s - loss: 2.5231 - acc: 0.1140 - val_loss: 2.3660 - val_acc: 0.1345\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 231s - loss: 2.4663 - acc: 0.1320 - val_loss: 2.3657 - val_acc: 0.1345\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 222s - loss: 2.4246 - acc: 0.1400 - val_loss: 2.3744 - val_acc: 0.1345\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 221s - loss: 2.4150 - acc: 0.1440 - val_loss: 2.3544 - val_acc: 0.1345\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 244s - loss: 2.4118 - acc: 0.1200 - val_loss: 2.3523 - val_acc: 0.1560\n",
      "Training model 7 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 580s - loss: nan - acc: 0.1300 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 355s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 363s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 385s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 358s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 360s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 413s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 420s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 415s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 419s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Training model 8 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 29s - loss: 65.5579 - acc: 0.5600 - val_loss: 2.1297 - val_acc: 0.1749\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 29s - loss: 9.4563 - acc: 0.6700 - val_loss: 1.2942 - val_acc: 0.5795\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 31s - loss: 4.0441 - acc: 0.7120 - val_loss: 1.1762 - val_acc: 0.6363\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 33s - loss: 3.8447 - acc: 0.6860 - val_loss: 1.2447 - val_acc: 0.6502\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 31s - loss: 3.9758 - acc: 0.7060 - val_loss: 0.9916 - val_acc: 0.7000\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 30s - loss: 3.5002 - acc: 0.7200 - val_loss: 1.0058 - val_acc: 0.6876\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 29s - loss: 3.6563 - acc: 0.7160 - val_loss: 1.2626 - val_acc: 0.5371\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 29s - loss: 3.5769 - acc: 0.7300 - val_loss: 1.0202 - val_acc: 0.6423\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 29s - loss: 3.4662 - acc: 0.7040 - val_loss: 0.8010 - val_acc: 0.7439\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 29s - loss: 3.8556 - acc: 0.7300 - val_loss: 0.9766 - val_acc: 0.6303\n",
      "Training model 9 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 415s - loss: 17.1257 - acc: 0.2340 - val_loss: 2.1687 - val_acc: 0.4031\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 444s - loss: 16.2093 - acc: 0.4020 - val_loss: 1.9268 - val_acc: 0.4459\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 3037s - loss: 15.4312 - acc: 0.4340 - val_loss: 1.7760 - val_acc: 0.4798\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 335s - loss: 14.7004 - acc: 0.4700 - val_loss: 1.6667 - val_acc: 0.5396\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 347s - loss: 13.9788 - acc: 0.5240 - val_loss: 1.5341 - val_acc: 0.5381\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 358s - loss: 13.3355 - acc: 0.5400 - val_loss: 1.4547 - val_acc: 0.6363\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 359s - loss: 12.7603 - acc: 0.5660 - val_loss: 1.3574 - val_acc: 0.6876\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 135749s - loss: 12.1716 - acc: 0.6260 - val_loss: 1.2579 - val_acc: 0.7339\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 409s - loss: 11.6515 - acc: 0.6540 - val_loss: 1.2225 - val_acc: 0.7110\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 384s - loss: 11.1354 - acc: 0.7020 - val_loss: 1.0855 - val_acc: 0.7997\n",
      "Training model 10 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 534s - loss: 7.4479 - acc: 0.1620 - val_loss: 2.0270 - val_acc: 0.4718\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 408s - loss: 6.2308 - acc: 0.4240 - val_loss: 1.7172 - val_acc: 0.5800\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 536s - loss: 5.2220 - acc: 0.5780 - val_loss: 1.3732 - val_acc: 0.7434\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 1126s - loss: 4.4715 - acc: 0.6160 - val_loss: 1.1751 - val_acc: 0.7185\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 541s - loss: 3.7710 - acc: 0.7180 - val_loss: 0.9976 - val_acc: 0.7987\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 465s - loss: 3.2456 - acc: 0.7540 - val_loss: 0.8808 - val_acc: 0.7942\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 508s - loss: 2.9573 - acc: 0.7340 - val_loss: 0.8455 - val_acc: 0.7748\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 456s - loss: 2.6618 - acc: 0.7500 - val_loss: 0.7690 - val_acc: 0.8251\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 486s - loss: 2.4411 - acc: 0.7880 - val_loss: 0.7778 - val_acc: 0.8236\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 468s - loss: 2.2958 - acc: 0.7780 - val_loss: 0.7876 - val_acc: 0.7733\n",
      "Training model 11 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 14s - loss: 2.8688 - acc: 0.5980 - val_loss: 1.0018 - val_acc: 0.7205\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 15s - loss: 3.1055 - acc: 0.8180 - val_loss: 0.8314 - val_acc: 0.7598\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 15s - loss: 2.7676 - acc: 0.8500 - val_loss: 0.7051 - val_acc: 0.8645\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 14s - loss: 2.4058 - acc: 0.8700 - val_loss: 0.6680 - val_acc: 0.8719\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 15s - loss: 2.1007 - acc: 0.8760 - val_loss: 0.6498 - val_acc: 0.8161\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 15s - loss: 1.7445 - acc: 0.9360 - val_loss: 0.5231 - val_acc: 0.8769\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 15s - loss: 1.5514 - acc: 0.9480 - val_loss: 0.5572 - val_acc: 0.8690\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 14s - loss: 1.4566 - acc: 0.9200 - val_loss: 0.6413 - val_acc: 0.8012\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 14s - loss: 1.3054 - acc: 0.9360 - val_loss: 0.6198 - val_acc: 0.8052\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 14s - loss: 1.2272 - acc: 0.9200 - val_loss: 0.5590 - val_acc: 0.8475\n",
      "Training model 12 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 54s - loss: 448.4724 - acc: 0.2780 - val_loss: 2.1776 - val_acc: 0.3981\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 53s - loss: 38.7044 - acc: 0.3180 - val_loss: 2.1942 - val_acc: 0.2581\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 54s - loss: 17.4477 - acc: 0.2880 - val_loss: 2.4626 - val_acc: 0.1345\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 60s - loss: 9.3126 - acc: 0.3460 - val_loss: 2.4128 - val_acc: 0.1345\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 60s - loss: 9.3698 - acc: 0.3560 - val_loss: 2.0391 - val_acc: 0.2083\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 60s - loss: 10.4977 - acc: 0.3360 - val_loss: 2.6773 - val_acc: 0.1345\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 60s - loss: 9.1226 - acc: 0.3280 - val_loss: 2.9139 - val_acc: 0.1560\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 60s - loss: 9.6260 - acc: 0.3320 - val_loss: 1.9001 - val_acc: 0.2496\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 59s - loss: 11.4104 - acc: 0.3400 - val_loss: 2.3574 - val_acc: 0.1734\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 59s - loss: 10.2112 - acc: 0.3080 - val_loss: 3.1187 - val_acc: 0.1151\n",
      "Training model 13 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 29s - loss: 220.4660 - acc: 0.2080 - val_loss: 2.5154 - val_acc: 0.1355\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 30s - loss: 21.5434 - acc: 0.2500 - val_loss: 2.5579 - val_acc: 0.1345\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 38s - loss: 7.3049 - acc: 0.3220 - val_loss: 2.9330 - val_acc: 0.1345\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 32s - loss: 6.3343 - acc: 0.2920 - val_loss: 2.6060 - val_acc: 0.1560\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 29s - loss: 5.6812 - acc: 0.2960 - val_loss: 2.5228 - val_acc: 0.1345\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 29s - loss: 5.5297 - acc: 0.3220 - val_loss: 14.7285 - val_acc: 0.0060\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 29s - loss: 5.4938 - acc: 0.3720 - val_loss: 2.2171 - val_acc: 0.1988\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 29s - loss: 4.3335 - acc: 0.3460 - val_loss: 10.3634 - val_acc: 0.1151\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 29s - loss: 5.9388 - acc: 0.3680 - val_loss: 3.6002 - val_acc: 0.1345\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 29s - loss: 6.9201 - acc: 0.3440 - val_loss: 2.2306 - val_acc: 0.2905\n",
      "Training model 14 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 31s - loss: 2.1219 - acc: 0.4760 - val_loss: 1.6700 - val_acc: 0.5107\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 31s - loss: 1.6357 - acc: 0.6940 - val_loss: 0.8203 - val_acc: 0.7698\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 29s - loss: 1.3264 - acc: 0.7840 - val_loss: 0.8948 - val_acc: 0.7544\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 29s - loss: 1.2689 - acc: 0.8160 - val_loss: 0.8587 - val_acc: 0.8052\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 30s - loss: 1.1519 - acc: 0.8220 - val_loss: 0.8313 - val_acc: 0.8336\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 30s - loss: 1.0081 - acc: 0.8640 - val_loss: 0.7664 - val_acc: 0.7723\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 29s - loss: 0.9529 - acc: 0.8520 - val_loss: 0.7608 - val_acc: 0.8012\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 30s - loss: 0.8860 - acc: 0.9000 - val_loss: 0.8481 - val_acc: 0.7738\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 30s - loss: 0.8123 - acc: 0.8880 - val_loss: 0.6417 - val_acc: 0.8540\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 30s - loss: 0.8584 - acc: 0.8900 - val_loss: 0.6183 - val_acc: 0.8625\n",
      "Training model 15 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 24s - loss: 22.5016 - acc: 0.5360 - val_loss: 1.2584 - val_acc: 0.6313\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 24s - loss: 18.1711 - acc: 0.7660 - val_loss: 1.2033 - val_acc: 0.7828\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 24s - loss: 14.1875 - acc: 0.8420 - val_loss: 1.1299 - val_acc: 0.7838\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 24s - loss: 11.0386 - acc: 0.9020 - val_loss: 1.2437 - val_acc: 0.7793\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 24s - loss: 8.7088 - acc: 0.8900 - val_loss: 1.1157 - val_acc: 0.7853\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 24s - loss: 6.9807 - acc: 0.9120 - val_loss: 1.1901 - val_acc: 0.7703\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 24s - loss: 5.6851 - acc: 0.9200 - val_loss: 1.2711 - val_acc: 0.7265\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 24s - loss: 4.7663 - acc: 0.9220 - val_loss: 1.1099 - val_acc: 0.7972\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 24s - loss: 4.0548 - acc: 0.9240 - val_loss: 1.1195 - val_acc: 0.7618\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 24s - loss: 3.5922 - acc: 0.9040 - val_loss: 1.1285 - val_acc: 0.7853\n",
      "Training model 16 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 283s - loss: 5.1601 - acc: 0.1220 - val_loss: 2.3220 - val_acc: 0.2845\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 283s - loss: 3.8871 - acc: 0.2000 - val_loss: 2.2266 - val_acc: 0.2496\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 291s - loss: 3.2346 - acc: 0.2580 - val_loss: 1.7876 - val_acc: 0.3747\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 290s - loss: 2.7455 - acc: 0.3540 - val_loss: 1.6126 - val_acc: 0.4021\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 288s - loss: 2.4155 - acc: 0.4080 - val_loss: 1.4812 - val_acc: 0.4439\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 289s - loss: 2.2479 - acc: 0.4400 - val_loss: 1.2665 - val_acc: 0.5590\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 317s - loss: 2.0704 - acc: 0.5140 - val_loss: 1.2907 - val_acc: 0.5929\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 296s - loss: 2.0673 - acc: 0.4480 - val_loss: 1.4686 - val_acc: 0.6263\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 420s - loss: 1.8570 - acc: 0.5200 - val_loss: 1.2377 - val_acc: 0.6916\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 732s - loss: 1.5882 - acc: 0.5900 - val_loss: 0.9346 - val_acc: 0.7185\n",
      "Training model 17 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 88s - loss: 5.8782 - acc: 0.6340 - val_loss: 1.0966 - val_acc: 0.6781\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 89s - loss: 7.3977 - acc: 0.7280 - val_loss: 1.0488 - val_acc: 0.6756\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 105s - loss: 5.9324 - acc: 0.7620 - val_loss: 0.8719 - val_acc: 0.8490\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 94s - loss: 4.6199 - acc: 0.8320 - val_loss: 0.9350 - val_acc: 0.7693\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 87s - loss: 3.8005 - acc: 0.8220 - val_loss: 0.8604 - val_acc: 0.7065\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 86s - loss: 3.0795 - acc: 0.8520 - val_loss: 0.8192 - val_acc: 0.7598\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 86s - loss: 2.5568 - acc: 0.8680 - val_loss: 0.7295 - val_acc: 0.8206\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 84s - loss: 2.1212 - acc: 0.9200 - val_loss: 0.8224 - val_acc: 0.7210\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 95s - loss: 1.8707 - acc: 0.9040 - val_loss: 0.5099 - val_acc: 0.8710\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 84s - loss: 1.6601 - acc: 0.9120 - val_loss: 0.8000 - val_acc: 0.7314\n",
      "Training model 18 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 681s - loss: 2.6489 - acc: 0.1620 - val_loss: 2.3026 - val_acc: 0.3896\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 623s - loss: 2.5414 - acc: 0.2560 - val_loss: 2.1367 - val_acc: 0.5132\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 653s - loss: 2.4118 - acc: 0.3420 - val_loss: 2.0729 - val_acc: 0.5526\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 707s - loss: 2.3150 - acc: 0.4160 - val_loss: 2.0327 - val_acc: 0.5162\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 678s - loss: 2.2600 - acc: 0.4020 - val_loss: 1.9163 - val_acc: 0.6188\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 778s - loss: 2.2006 - acc: 0.4660 - val_loss: 1.8634 - val_acc: 0.6776\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 774s - loss: 2.1288 - acc: 0.4760 - val_loss: 1.8659 - val_acc: 0.6069\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 408s - loss: 2.1251 - acc: 0.5000 - val_loss: 1.7883 - val_acc: 0.7020\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 345s - loss: 2.0698 - acc: 0.5480 - val_loss: 1.7166 - val_acc: 0.6916\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 328s - loss: 1.9586 - acc: 0.5620 - val_loss: 1.6986 - val_acc: 0.6841\n",
      "Training model 19 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 262s - loss: 2.4219 - acc: 0.1780 - val_loss: 1.9794 - val_acc: 0.4096\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 242s - loss: 1.9747 - acc: 0.3920 - val_loss: 1.5222 - val_acc: 0.4773\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 244s - loss: 1.6412 - acc: 0.4880 - val_loss: 1.5028 - val_acc: 0.5356\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 296s - loss: 1.4910 - acc: 0.5820 - val_loss: 1.1081 - val_acc: 0.7374\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 268s - loss: 1.3055 - acc: 0.6300 - val_loss: 0.8814 - val_acc: 0.7997\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 266s - loss: 1.2218 - acc: 0.6460 - val_loss: 0.7413 - val_acc: 0.7902\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 267s - loss: 1.1130 - acc: 0.6800 - val_loss: 0.7306 - val_acc: 0.8047\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 267s - loss: 1.1434 - acc: 0.6700 - val_loss: 0.7948 - val_acc: 0.7578\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 267s - loss: 0.9816 - acc: 0.7180 - val_loss: 0.6148 - val_acc: 0.8201\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 273s - loss: 0.9183 - acc: 0.7480 - val_loss: 0.4787 - val_acc: 0.8814\n",
      "Training model 20 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 143s - loss: 3.0790 - acc: 0.1960 - val_loss: 2.0084 - val_acc: 0.2835\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 155s - loss: 2.0352 - acc: 0.3800 - val_loss: 2.5040 - val_acc: 0.1799\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 152s - loss: 2.5942 - acc: 0.2500 - val_loss: 1.7871 - val_acc: 0.4205\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 130s - loss: nan - acc: 0.3220 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 118s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 109s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 113s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 130s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 117s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 119s - loss: nan - acc: 0.1140 - val_loss: nan - val_acc: 0.1151\n",
      "Training model 21 DeepConvLSTM\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 168s - loss: 2.6467 - acc: 0.2980 - val_loss: 1.8913 - val_acc: 0.6303\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 171s - loss: 2.2255 - acc: 0.5340 - val_loss: 1.5588 - val_acc: 0.7887\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 173s - loss: 1.9737 - acc: 0.6260 - val_loss: 1.3359 - val_acc: 0.8201\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 170s - loss: 1.7975 - acc: 0.6500 - val_loss: 1.1912 - val_acc: 0.8052\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 175s - loss: 1.6400 - acc: 0.7080 - val_loss: 0.9977 - val_acc: 0.8705\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 172s - loss: 1.5035 - acc: 0.7200 - val_loss: 0.8876 - val_acc: 0.8565\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 173s - loss: 1.4317 - acc: 0.7580 - val_loss: 0.9215 - val_acc: 0.8082\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 175s - loss: 1.3740 - acc: 0.7700 - val_loss: 0.8274 - val_acc: 0.8590\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 172s - loss: 1.3625 - acc: 0.7560 - val_loss: 0.8034 - val_acc: 0.8500\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 168s - loss: 1.2172 - acc: 0.7980 - val_loss: 0.7272 - val_acc: 0.8406\n",
      "Training model 22 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 44s - loss: 2052.9905 - acc: 0.1520 - val_loss: 2.3473 - val_acc: 0.3209\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 45s - loss: 148.2609 - acc: 0.3000 - val_loss: 10.2992 - val_acc: 0.1151\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 45s - loss: 22.2990 - acc: 0.2600 - val_loss: 4.6406 - val_acc: 0.1151\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 44s - loss: 17.0808 - acc: 0.2740 - val_loss: 2.7048 - val_acc: 0.0060\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 45s - loss: 13.6464 - acc: 0.2940 - val_loss: 7.4735 - val_acc: 0.1151\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 45s - loss: 13.6135 - acc: 0.2560 - val_loss: 14.1535 - val_acc: 0.0060\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 45s - loss: 15.9514 - acc: 0.2720 - val_loss: 10.8188 - val_acc: 0.0060\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 44s - loss: 15.1384 - acc: 0.2900 - val_loss: 8.1994 - val_acc: 0.1211\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 51s - loss: 39.5710 - acc: 0.2680 - val_loss: 12.2525 - val_acc: 0.0060\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 47s - loss: 25.2268 - acc: 0.3280 - val_loss: 2.2126 - val_acc: 0.2262\n",
      "Training model 23 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 44s - loss: 1.7400 - acc: 0.5540 - val_loss: 1.0824 - val_acc: 0.8102\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 40s - loss: 1.1292 - acc: 0.8140 - val_loss: 0.9199 - val_acc: 0.8027\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 42s - loss: 0.9626 - acc: 0.8620 - val_loss: 0.8209 - val_acc: 0.8570\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 43s - loss: 0.8433 - acc: 0.9320 - val_loss: 0.8998 - val_acc: 0.8221\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 40s - loss: 0.8737 - acc: 0.8920 - val_loss: 0.9042 - val_acc: 0.8535\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 40s - loss: 0.7763 - acc: 0.9360 - val_loss: 0.8962 - val_acc: 0.8575\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 40s - loss: 0.7390 - acc: 0.9500 - val_loss: 1.0260 - val_acc: 0.8037\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 38s - loss: 0.7322 - acc: 0.9500 - val_loss: 0.9730 - val_acc: 0.8326\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 39s - loss: 0.6659 - acc: 0.9680 - val_loss: 0.9909 - val_acc: 0.7912\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 39s - loss: 0.6721 - acc: 0.9620 - val_loss: 0.9288 - val_acc: 0.8186\n",
      "Training model 24 CNN\n",
      "Train on 500 samples, validate on 2007 samples\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 61s - loss: 5.3517 - acc: 0.6100 - val_loss: 1.0449 - val_acc: 0.6682\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 61s - loss: 4.9238 - acc: 0.8240 - val_loss: 0.8116 - val_acc: 0.8132\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 57s - loss: 3.7838 - acc: 0.8680 - val_loss: 0.9065 - val_acc: 0.7270\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 62s - loss: 2.9822 - acc: 0.9140 - val_loss: 0.5879 - val_acc: 0.9178\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 66s - loss: 2.4320 - acc: 0.9300 - val_loss: 0.6623 - val_acc: 0.9018\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 55s - loss: 2.1749 - acc: 0.9100 - val_loss: 0.6407 - val_acc: 0.8371\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 55s - loss: 1.9658 - acc: 0.8960 - val_loss: 0.5754 - val_acc: 0.8894\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 57s - loss: 1.7006 - acc: 0.9420 - val_loss: 0.6265 - val_acc: 0.9008\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 58s - loss: 1.5262 - acc: 0.9260 - val_loss: 0.6098 - val_acc: 0.8919\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 55s - loss: 1.4297 - acc: 0.9420 - val_loss: 0.5814 - val_acc: 0.9038\n",
      "182695.70508646965\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "for j in range(len(X_list)):\n",
    "    X_train, y_train, X_val, y_val = split_train_val(Xs, ys, j)\n",
    "    histories, val_accuracies, val_losses = find_architecture.train_models_on_samples(X_train, y_train_binary,\n",
    "                                                                           X_val, y_val_binary,\n",
    "                                                                           models,nr_epochs=10,\n",
    "                                                                           subset_size=500,\n",
    "                                                                           verbose=True,\n",
    "                                                                           outputfile=resultpath+\\\n",
    "                                                                                  'experiment'+str(j)+'.json')\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histories object produced by the previous step contains the history of classifier performance with every iteration of the training process. To ease inspecting this information we developed function plotTrainingProcess, which is demonstrated in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of comparing model performance is by putting all the information in a pandas dataframe, which we can store in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'filters': array([94]), 'learning_rate': 0.05...</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>11.924376</td>\n",
       "      <td>0.512207</td>\n",
       "      <td>1.655583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'filters': array([79, 64, 90]), 'learning_rat...</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>6.713034</td>\n",
       "      <td>0.835575</td>\n",
       "      <td>1.017291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  train_acc  train_loss  \\\n",
       "0  {'filters': array([94]), 'learning_rate': 0.05...   0.706667   11.924376   \n",
       "1  {'filters': array([79, 64, 90]), 'learning_rat...   0.923333    6.713034   \n",
       "\n",
       "    val_acc  val_loss  \n",
       "0  0.512207  1.655583  \n",
       "1  0.835575  1.017291  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelcomparisons = pd.DataFrame({'model':[str(params) for model, params, model_types in models],\n",
    "                       'train_acc': [history.history['acc'][-1] for history in histories],\n",
    "                       'train_loss': [history.history['loss'][-1] for history in histories],\n",
    "                       'val_acc': [history.history['val_acc'][-1] for history in histories],\n",
    "                       'val_loss': [history.history['val_loss'][-1] for history in histories]\n",
    "                       })\n",
    "modelcomparisons.to_csv(resultpath +'modelcomparisons.csv')\n",
    "\n",
    "modelcomparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to vizualize the performance of the various models using our vizualisation tool as explained in the mcfly repository README file: https://github.com/NLeSC/mcfly/blob/master/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check which model is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model type and parameters of the best model:\n",
      "CNN\n",
      "{'regularization_rate': 0.0016693552595679474, 'learning_rate': 0.0013927354361231595, 'filters': array([ 69,  71,  90, 100,  29,  41]), 'fc_hidden_nodes': 1314}\n"
     ]
    }
   ],
   "source": [
    "best_model_index = np.argmax(val_accuracies)\n",
    "best_model, best_params, best_model_types = models[best_model_index]\n",
    "print('Model type and parameters of the best model:')\n",
    "print(best_model_types)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/media/sf_VBox_Shared/timeseries//PAMAP2/PAMAP2_Dataset/results/bestmodel_sample_architecture.json',\n",
       " '/media/sf_VBox_Shared/timeseries//PAMAP2/PAMAP2_Dataset/results/bestmodel_sample_weights')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelname = 'bestmodel_sample'\n",
    "storage.savemodel(best_model,resultpath,modelname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the best model for real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have identified the best model architecture out of our random pool of models we can continue by training the model on the full training sample. For the purpose of speeding up the example we only train the full model on the first 1000 values. You will need to replace this by 'datasize = X_train.shape[0]' in a real world example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12497 samples, validate on 2007 samples\n",
      "Epoch 1/1\n",
      "12497/12497 [==============================] - 592s - loss: 2.0438 - acc: 0.9119 - val_loss: 0.2887 - val_acc: 0.9841\n"
     ]
    }
   ],
   "source": [
    "#We make a copy of the model, to start training from fresh\n",
    "best_model_copy = modelgen.generate_CNN_model(X_train.shape, num_classes, best_params['filters'], best_params['fc_hidden_nodes'],\n",
    "                       best_params['learning_rate'], best_params['regularization_rate'])\n",
    "nr_epochs = 1\n",
    "datasize = X_train.shape[0] #We're going to train the model on the complete data set\n",
    "#datasize = 1000 # subsample for the sake of this example\n",
    "history = best_model_copy.fit(X_train[:datasize,:,:], y_train_binary[:datasize,:],\n",
    "              nb_epoch=nr_epochs, validation_data=(X_val, y_val_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the training process:\n",
    "find_architecture.plotTrainingProcess(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_fullytrained = best_model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of best model: [0.28872849385374272, 0.98405580468360743]\n"
     ]
    }
   ],
   "source": [
    "score_val = best_model_fullytrained.evaluate(X_val, y_val_binary, verbose=False)\n",
    "print('Score of best model: ' + str(score_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving, loading and comparing reloaded model with orignal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modoel can be saved for future use. The savemodel function will save two separate files: a json file for the architecture and a npy (numpy array) file for the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelname = 'my_bestmodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/media/sf_VBox_Shared/timeseries//PAMAP2/PAMAP2_Dataset/results/my_bestmodel_architecture.json',\n",
       " '/media/sf_VBox_Shared/timeseries//PAMAP2/PAMAP2_Dataset/results/my_bestmodel_weights')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.savemodel(best_model_fullytrained,resultpath,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model_fullytrained = storage.loadmodel(resultpath,modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/sf_VBox_Shared/timeseries/PAMAP2_Dataset/results/bestmodel_sample_architecture.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bbd73981e2c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bestmodel_sample'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dafne/anaconda2/envs/mcfly/lib/python3.5/site-packages/mcfly/storage.py\u001b[0m in \u001b[0;36mloadmodel\u001b[0;34m(filepath, modelname)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mreproduced\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \"\"\"\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodelname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_architecture.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mjson_string_loaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mmodel_repro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string_loaded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/sf_VBox_Shared/timeseries/PAMAP2_Dataset/results/bestmodel_sample_architecture.json'"
     ]
    }
   ],
   "source": [
    "best_model_sample = storage.loadmodel(resultpath, 'bestmodel_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0013927354361231595\n",
    "best_model_fullytrained.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=learning_rate),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model_sample.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam(lr=learning_rate),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has been reloaded. Let's investigate whether it gives the same probability estimates as the original model in a small subset of the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced model inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although beyond the scope of mcfly it may be worth highlighting that the objects 'models', 'best_model_fullytrained' and 'best_model' are Keras objects. This means that you can use Keras functions like .predict and .evaluate on the objects to run advanced analyses. These functions are all documented in the Keras documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of best model: [1.5646683828375569, 0.52981849611063092]\n"
     ]
    }
   ],
   "source": [
    "## Test on Testset\n",
    "score_test = best_model_fullytrained.evaluate(X_test, y_test_binary, verbose=False)\n",
    "print('Score of best model: ' + str(score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2314, 512, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9208478596103324, 0.46672428694900603]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_sample.evaluate(X_test, y_test_binary, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007/2007 [==============================] - 40s    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28872849385374272, 0.98405580468360743]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_fullytrained.evaluate(X_val, y_val_binary, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3595505617977528"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_architecture.kNN_accuracy(X_train[:500,:,:], y_train_binary[:500,], X_test, y_test_binary, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44294967613353264"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_architecture.kNN_accuracy(X_train[:500,:,:], y_train_binary[:500,], X_val, y_val_binary, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.359982713915\n",
      "0.470852017937\n"
     ]
    }
   ],
   "source": [
    "print(find_architecture.kNN_accuracy(X_train[:1000,:,:], y_train_binary[:1000,], X_test, y_test_binary, k=1))\n",
    "print(find_architecture.kNN_accuracy(X_train[:1000,:,:], y_train_binary[:1000,], X_val, y_val_binary, k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
