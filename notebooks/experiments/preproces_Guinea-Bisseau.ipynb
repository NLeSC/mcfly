{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Guinea-Bissau data and save as numpy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import merge \n",
    "from os import listdir\n",
    "from numpy import genfromtxt, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datadir = \"/media/windows-share/EEG/EEGs_Nigeria_cleaned\"\n",
    "outputdir = \"/media/windows-share/EEG/EEGs_Nigeria_np\"\n",
    "filenames = listdir(datadir)\n",
    "D = []\n",
    "sf = 128\n",
    "nc = 14\n",
    "#Nfiles = len(filenames)\n",
    "#X = np.zeros((Nfiles,maxtslength,nc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id = list(map(int,list(map(lambda file: file[file.find('id')+2:file.find('dur')-1],filenames))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dur = list(map(int,list(map(lambda file: file[file.find('dur')+3:file.find('epoch')-1],filenames))))\n",
    "#epoch = list(map(int,list(map(lambda file: file[file.find('epoch')+5:file.find('gro')-1],filenames))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group = list(map(str,list(map(lambda file: file[file.find('gro')+3:file.find('.csv')],filenames))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "protocol = list(map(str,list(map(lambda file: file[file.find('yes')+3:file.find('id')-1],filenames))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mydata = id, dur, group\n",
    "df = pd.DataFrame.from_items([('id',id),('dur',dur),('group',group),('filenames',filenames),\n",
    "                              ('protocol',protocol)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_10seconds_open 272\n",
      "valid_10seconds_open 20\n",
      "test_10seconds_open 20\n",
      "train_10seconds_closed 255\n",
      "valid_10seconds_closed 20\n",
      "test_10seconds_closed 20\n"
     ]
    }
   ],
   "source": [
    "logstructure = []\n",
    "for mindur in [10]: # minimum duration of an epoch in seconds\n",
    "    for protocol in ['open','closed']:\n",
    "        df2 = df[(df['protocol']==protocol) & (df['dur'] >= mindur)]\n",
    "        maxtslength = mindur * sf\n",
    "        #Identify training, test and validation group\n",
    "        con = np.unique(df2[df2['group'] == 'control']['id'])\n",
    "        epi = np.unique(df2[df2['group'] == 'epilepsy']['id'])\n",
    "        Nid = len(con) + len(epi) #number of ids\n",
    "        prop = 0.5 # len(con) / Nid #proportion of controls\n",
    "        random.seed(300)\n",
    "        def getids(x,y,prop,N):\n",
    "            ix = np.sort(np.random.choice(x,round(N*prop),replace=False))\n",
    "            iy = np.sort(np.random.choice(y,round(N*(1-prop)),replace=False))\n",
    "            if (len(ix)+len(iy)) < 20:\n",
    "                print(prop,N,len(x),len(y))\n",
    "            x = [x for i,x in enumerate(x) if x not in ix]    \n",
    "            y = [x for i,x in enumerate(y) if x not in iy]    \n",
    "            icon = np.concatenate((ix,iy))\n",
    "            return icon, x, y\n",
    "        ival, con, epi = getids(con,epi,prop,N=20) # validation set\n",
    "        ites, con, epi = getids(con,epi,prop,N=20) # test set\n",
    "        itra = np.concatenate((con, epi)) # training set\n",
    "        #print(len(ival),len(ites),len(itra))\n",
    "        # Now use identifies per group to load the data\n",
    "        for subset in ['train','valid','test']:\n",
    "            conditionname = subset+'_'+str(mindur)+'seconds_'+protocol\n",
    "            if subset == 'train':\n",
    "                tmp = df2[df2.id.isin(itra)]\n",
    "                filenames = tmp['filenames']\n",
    "            if subset == 'valid':\n",
    "                tmp = df2[(df2.id.isin(ival))]\n",
    "                tmp = tmp.sort_values(by=['id']).groupby('id').first() # select first available epoch\n",
    "                filenames = tmp['filenames']\n",
    "            if subset == 'test':\n",
    "                tmp = df2[(df2.id.isin(ites))]\n",
    "                tmp = tmp.sort_values(by=['id']).groupby('id').first() # select first available epoch\n",
    "                filenames = tmp['filenames']\n",
    "            X = np.zeros((0,maxtslength,nc)) #len(filenames)\n",
    "            y = np.zeros((0,1)) #len(filenames)\n",
    "            \n",
    "            print(conditionname + ' ' + str(len(filenames)))\n",
    "            for file in filenames:\n",
    "                path = datadir + '/' + file\n",
    "                D = pd.read_csv(path, sep=',',header=0,usecols=list(range(0,14)))\n",
    "                if D.shape[0] > maxtslength:\n",
    "                    slicesize = sf * 10\n",
    "                    for slicei in range(int(len(D)/slicesize)):\n",
    "                        sta = (((slicei)*slicesize))\n",
    "                        end = ((slicei+1)*slicesize)\n",
    "                        D2 = np.array(D[sta:end]) # take first part or should these be a random selection?\n",
    "                    #D = np.array(D[0:maxtslength]) # take first part or should these be a random selection?\n",
    "                        D2 = np.reshape(D2,(1,D2.shape[0],D2.shape[1]))\n",
    "                        m = D2.mean(axis=1,keepdims=True)\n",
    "                        D2 = D2 - m # subtract mean\n",
    "                        X = np.vstack((X,D2))\n",
    "                        logstructure.append([subset,mindur,protocol,file])\n",
    "                        diagnosis = tmp.group[(tmp.filenames == file)]\n",
    "                        y = np.vstack((y,diagnosis))\n",
    "            \n",
    "            fnameX = outputdir + '/X_' + conditionname\n",
    "            fnamey = outputdir + '/y_' + conditionname\n",
    "            np.save(file=fnameX,arr=X)\n",
    "            #y = np.array(tmp['group'])\n",
    "            np.save(file=fnamey,arr=y)            \n",
    "np.savetxt(outputdir + '/log.csv', logstructure,\n",
    "           delimiter=\",\", fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/windows-share/EEG/EEGs_Nigeria_np/X_test_10seconds_closed\n",
      "/media/windows-share/EEG/EEGs_Nigeria_np/y_test_10seconds_closed\n"
     ]
    }
   ],
   "source": [
    "print(fnameX)\n",
    "print(fnamey)\n",
    "testreadX = np.load(file=fnameX+'.npy')\n",
    "testready = np.load(file=fnamey+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 1280, 14)\n",
      "(163, 1)\n"
     ]
    }
   ],
   "source": [
    "print(testreadX.shape)\n",
    "print(testready.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
